
# Quantized Side Tuning: Fast and Memory-Efficient Tuning of Quantized Large Language Models

## Quick Start

- [Introduction](#introduction)

- [Installation](#installation)
- [Usage](#usage)
- [License](#license)
- [Acknowledgements](#acknowledgements)

## Introduction
This the GitHub repository for our CSE291 project. We explore Quantized Side tuning in this project.


## Installation

1. git clone the repo
   ```
   git clone https://github.com/Singla17/291_LLM_Reasoning.git
2. install requirements
   ```
   cd QST
   pip install -r requirements.txt
   
## Usage
We provide three branches to experiment with in this repository: `Master`, `adaptive-quantization-llrd`, `adaptive-quantization-llrd`.   
Use `master` for the reproduction of QST and the other two branches for the respective extensions.


## License
This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.
## Acknowlegement
This code is based on [QST](https://github.com/YouAreSpecialToMe/QST), [QLoRA](https://github.com/artidoro/qlora), Standford [Alpaca](https://github.com/artidoro/qlora), and [FastChat](https://github.com/lm-sys/FastChat) repos.

